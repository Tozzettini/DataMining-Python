

# Python-DataMining
Contains all experiments, projects, and exercises

---

# Exercise 1: Predicting House Prices _(Predictive Modeling)_

**Objective**: Develop a prediction model for house prices based on the total living area using the provided dataset. This involves reading the 'marketing.csv' file and displaying its first five lines for initial exploration. Then, create scatterplots to visualize the correlation between the selling price and other attributes, with a specific focus on the relationship with the total living area. Next, fit a regression model to predict house prices based on total living area, followed by evaluating the model's quality by calculating the coefficient of determination (R^2). Finally, utilize the trained regression model to make predictions for new data points.

---

# Exercise 2: Fashion-MNIST _(Data visualization)_

**Objective**: This assignment focuses on analyzing the Fashion-MNIST dataset, consisting of Zalando's article images, with a training set of 60,000 instances and a test set of 10,000 samples. Each instance is a 28x28 grayscale image associated with one of ten class labels, including T-shirt/top, trousers, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, and Ankle boot. The tasks include implementing Principal Component Analysis (PCA) to reduce dimensionality and training Random Forest classifiers on both the original and reduced datasets to evaluate training time and model performance. Additionally, Softmax regression is applied to the original and reduced datasets to compare training time and model accuracy. In Part 2, dimensionality reduction using t-SNE (t-distributed Stochastic Neighbor Embedding) is explored, plotting scatterplots to visualize the data distribution for different class labels and combinations thereof. The objective is to analyze training time, model performance, and data visualization techniques to draw insights from the Fashion-MNIST dataset.

--- 

# Exercise 3: Who Survived the Titanic Disaster? _(Predictive Modeling)_

**Objective**: This Titanic example employs decision trees for predictive modeling, chosen for their interpretability and ease of understanding by humans. The model's transparency allows for a clear sequence of decisions, aiding in tasks like medical diagnosis or credit approval, where explaining the reasoning behind decisions is crucial. The goal is to predict whether a Titanic passenger would have survived based on their age, class, and sex, chosen due to their potential influence on survival likelihood. By utilizing decision trees, the aim is to avoid overfitting, particularly with features prone to such issues, and to enhance generalization capabilities. This assignment involves data mining and tree-building techniques using the provided Jupyter Notebook and dataset, facilitating the exploration of the Titanic dataset and the construction of interpretable decision trees.

--- 

# Exercise 4: Neural network trained on Digit dataset _(Predictive Modeling)_

**Objective**: 
In this assignment, I experimented with the Digits dataset, which contains handwritten digits, with the goal of building a basic neural network capable of recognizing these digits. The assignment involved importing the dataset, dividing it into training, validation, and test sets, and subsequently training a neural network model without convolutional neural network (CNN) architecture. The model's performance was assessed using two primary metrics: accuracy and the confusion matrix. Evaluation included analyzing the model's accuracy and loss, as well as visualizing its confusion matrix, all aimed at pushing and showing the neural network's effectiveness in identifying digits.

--- 
